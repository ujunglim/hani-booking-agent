{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1854accc",
   "metadata": {},
   "source": [
    "# LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e690984f",
   "metadata": {},
   "source": [
    "## Simple Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b04ae79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can't provide real-time weather updates, but you can check the weather for your location by using a weather service like:\n",
      "\n",
      "- [Weather.com](https://weather.com)  \n",
      "- [AccuWeather](https://www.accuweather.com)  \n",
      "- [The Weather Channel](https://www.weather.gov) (for the U.S.)  \n",
      "- Your smartphone's default weather app  \n",
      "\n",
      "Let me know if you'd like help interpreting weather terms or forecasts!"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "llm_model = ChatOpenAI(\n",
    "    model='deepseek-chat',\n",
    "    base_url='https://api.deepseek.com',\n",
    "    api_key='sk-7a3d4f4b2ca54d2dbb09e88d3572a242',\n",
    "    \n",
    "    streaming=True,  # 启用流式输出\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]  # 添加流式回调处理器\n",
    ")\n",
    "\n",
    "messages1 = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"What is the weather tomorrow?\")\n",
    "]\n",
    "\n",
    "response = llm_model.invoke(messages1)\n",
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22894f67",
   "metadata": {},
   "source": [
    "## Conversation with history - Legacy（Deprecated）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5ee73e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "你: \n",
      "日本的首都是什么\n",
      "\n",
      "助手: \n",
      "东京。"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# 配置DeepSeek API\n",
    "model = ChatOpenAI(\n",
    "    model='deepseek-chat',\n",
    "    base_url='https://api.deepseek.com',\n",
    "    api_key='sk-7a3d4f4b2ca54d2dbb09e88d3572a242',\n",
    "    streaming=True,  # 保留流式输出功能\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]  # 添加流式回调处理器\n",
    ")\n",
    "\n",
    "# 创建聊天提示模板\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\\n\\t你是一个智能助手，与用户进行友好对话。回答尽量简洁\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),  # 存储对话历史\n",
    "    (\"human\", \"\\n\\t{input}\")  # 当前用户输入\n",
    "])\n",
    "\n",
    "# 初始化内存\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "# 创建对话链\n",
    "conversation = LLMChain(\n",
    "    llm=model,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    "    verbose=False  # 显示详细的处理过程\n",
    ")\n",
    "\n",
    "# 多轮对话示例\n",
    "while True:\n",
    "    user_input = input(\"你: \")\n",
    "    if user_input.lower() == \"退出\":\n",
    "        break\n",
    "    \n",
    "    print(f\"\\n\\n你: \\n{user_input}\")  # 确保输出立即显示\n",
    "    print(\"\\n助手: \\n\", end=\"\")  # 确保输出立即显示\n",
    "    # 执行对话并获取流式响应\n",
    "    response = conversation.run(user_input)\n",
    "    # print(f\"助手: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6875560a",
   "metadata": {},
   "source": [
    "## Conversation with history - Simple LCEL \n",
    "Simple LCEL with RunnableWithMessageHistory and a single built-in memory class - InMemoryChatMessageHistory\n",
    "\n",
    "LCEL means LangChain Expression Language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19db6c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "你: \n",
      "日本在哪里\n",
      "\n",
      "助手: \n",
      "日本位于东亚，是一个岛国，在太平洋西北部，与中国、韩国隔海相望。\n",
      "\n",
      "你: \n",
      "有哪些美食\n",
      "\n",
      "助手: \n",
      "日本美食很多，主要有：  \n",
      "- **寿司** 🍣  \n",
      "- **拉面** 🍜  \n",
      "- **天妇罗** 🍤  \n",
      "- **刺身**（生鱼片）  \n",
      "- **章鱼烧** 🐙  \n",
      "- **和牛** 🥩  \n",
      "- **抹茶甜点** 🍵  \n",
      "\n",
      "都很有特色，值得一试！ 😋"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model='deepseek-chat',\n",
    "    base_url='https://api.deepseek.com',\n",
    "    api_key='sk-7a3d4f4b2ca54d2dbb09e88d3572a242',\n",
    "    streaming=True,  # 保留流式输出功能\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]  # 添加流式回调处理器\n",
    ")\n",
    "\n",
    "# 创建聊天提示模板\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\\n\\t你是一个智能助手，与用户进行友好对话。回答尽量简洁\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),  # 存储对话历史\n",
    "    (\"human\", \"\\n\\t{input}\")  # 当前用户输入\n",
    "])\n",
    "\n",
    "memory = InMemoryChatMessageHistory()\n",
    "\n",
    "chain = prompt | model\n",
    "chain = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    lambda session_id: memory,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "# 多轮对话示例\n",
    "while True:\n",
    "    user_input = input(\"你: \")\n",
    "    if user_input.lower() == \"退出\":\n",
    "        break\n",
    "    \n",
    "    print(f\"\\n\\n你: \\n{user_input}\")  # 确保输出立即显示\n",
    "    print(\"\\n助手: \\n\", end=\"\")  # 确保输出立即显示\n",
    "    chain.invoke({\"input\": user_input}, config={\"configurable\": {\"session_id\": \"123\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8aaf5b4",
   "metadata": {},
   "source": [
    "## Conversation with history - LCEL with sessions\n",
    "LCEL with RunnableWithMessageHistory and self-implemented memory class - InMemoryHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f50ca870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "你: \n",
      "委内瑞拉的首都是什么\n",
      "\n",
      "助手: \n",
      "加拉加斯。\n",
      "\n",
      "你: \n",
      "有哪些美食\n",
      "\n",
      "助手: \n",
      "委内瑞拉特色美食包括：  \n",
      "\n",
      "1. **Arepa**（玉米饼）—— 用玉米面做的饼，可夹各种馅料。  \n",
      "2. **Pabellón Criollo**（国菜）—— 碎牛肉、黑豆、米饭和炸芭蕉的组合。  \n",
      "3. **Cachapa**（甜玉米饼）—— 类似薄煎饼，常配奶酪。  \n",
      "4. **Tequeños**（芝士条）—— 酥皮包裹芝士，油炸小吃。  \n",
      "5. **Hallaca**（圣诞粽子）—— 芭蕉叶包裹的玉米面团，内含肉馅。  \n",
      "\n",
      "简单又美味！ 😊"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory\n",
    "from langchain_core.messages import BaseMessage, AIMessage\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model='deepseek-chat',\n",
    "    base_url='https://api.deepseek.com',\n",
    "    api_key='sk-7a3d4f4b2ca54d2dbb09e88d3572a242',\n",
    "    streaming=True,  # 保留流式输出功能\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]  # 添加流式回调处理器\n",
    ")\n",
    "\n",
    "# 创建聊天提示模板\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\\n\\t你是一个智能助手，与用户进行友好对话。回答尽量简洁\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),  # 存储对话历史\n",
    "    (\"human\", \"\\n\\t{input}\")  # 当前用户输入\n",
    "])\n",
    "\n",
    "class InMemoryHistory(BaseChatMessageHistory, BaseModel):\n",
    "    messages: list[BaseMessage] = Field(default_factory=list)\n",
    "\n",
    "    def add_messages(self, messages: list[BaseMessage]) -> None:\n",
    "        \"\"\"Add a list of messages to the store\"\"\"\n",
    "        self.messages.extend(messages)\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self.messages = []\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_by_session_id(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "chain = prompt | model\n",
    "chain = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_by_session_id,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "# 多轮对话示例\n",
    "while True:\n",
    "    user_input = input(\"你: \")\n",
    "    if user_input.lower() == \"退出\":\n",
    "        break\n",
    "    \n",
    "    print(f\"\\n\\n你: \\n{user_input}\")  # 确保输出立即显示\n",
    "    print(\"\\n助手: \\n\", end=\"\")  # 确保输出立即显示\n",
    "    chain.invoke({\"input\": user_input}, config={\"configurable\": {\"session_id\": \"123\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dff5d9",
   "metadata": {},
   "source": [
    "## Structured Output (JSON) With Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92081bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"response\": {\n",
      "    \"location\": \"Beijing\",\n",
      "    \"date\": \"2023-11-02\",\n",
      "    \"weather\": \"Sunny\",\n",
      "    \"temperature\": {\n",
      "      \"current\": \"15°C\",\n",
      "      \"high\": \"18°C\",\n",
      "      \"low\": \"8°C\"\n",
      "    },\n",
      "    \"humidity\": \"30%\",\n",
      "    \"wind\": {\n",
      "      \"speed\": \"10 km/h\",\n",
      "      \"direction\": \"North\"\n",
      "    },\n",
      "    \"air_quality\": {\n",
      "      \"index\": \"85\",\n",
      "      \"level\": \"Moderate\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "```"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='```json\\n{\\n  \"response\": {\\n    \"location\": \"Beijing\",\\n    \"date\": \"2023-11-02\",\\n    \"weather\": \"Sunny\",\\n    \"temperature\": {\\n      \"current\": \"15°C\",\\n      \"high\": \"18°C\",\\n      \"low\": \"8°C\"\\n    },\\n    \"humidity\": \"30%\",\\n    \"wind\": {\\n      \"speed\": \"10 km/h\",\\n      \"direction\": \"North\"\\n    },\\n    \"air_quality\": {\\n      \"index\": \"85\",\\n      \"level\": \"Moderate\"\\n    }\\n  }\\n}\\n```', additional_kwargs={}, response_metadata={'finish_reason': 'stop'}, id='run--f4ef3b40-57cb-4af9-a2a4-b63363895291-0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "llm_model = ChatOpenAI(\n",
    "    model=\"deepseek-chat\",\n",
    "    base_url='https://api.deepseek.com',\n",
    "    api_key='sk-7a3d4f4b2ca54d2dbb09e88d3572a242',\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a tool assistant, your response is a pure json output.\"),\n",
    "    HumanMessage(content=\"what is the weather and temperature in beijing today?\")\n",
    "]\n",
    "\n",
    "llm_model(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3751c4d",
   "metadata": {},
   "source": [
    "## Structured Output (JSON) With JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c609146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "format_instructions:  The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"name\": {\"description\": \"Building name\", \"title\": \"Name\", \"type\": \"string\"}, \"address\": {\"description\": \"Building address\", \"title\": \"Address\", \"type\": \"string\"}, \"city\": {\"description\": \"City where the building is located\", \"title\": \"City\", \"type\": \"string\"}, \"country\": {\"description\": \"Country where the building is located\", \"title\": \"Country\", \"type\": \"string\"}, \"completion_year\": {\"description\": \"Year of completion of the building\", \"title\": \"Completion Year\", \"type\": \"integer\"}}, \"required\": [\"name\", \"address\", \"city\", \"country\", \"completion_year\"]}\n",
      "```\n",
      "**************************************************\n",
      "prompt:  input_variables=['query'] input_types={} partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"name\": {\"description\": \"Building name\", \"title\": \"Name\", \"type\": \"string\"}, \"address\": {\"description\": \"Building address\", \"title\": \"Address\", \"type\": \"string\"}, \"city\": {\"description\": \"City where the building is located\", \"title\": \"City\", \"type\": \"string\"}, \"country\": {\"description\": \"Country where the building is located\", \"title\": \"Country\", \"type\": \"string\"}, \"completion_year\": {\"description\": \"Year of completion of the building\", \"title\": \"Completion Year\", \"type\": \"integer\"}}, \"required\": [\"name\", \"address\", \"city\", \"country\", \"completion_year\"]}\\n```'} template='Answer the user query.\\n{format_instructions}\\n{query}\\n'\n",
      "**************************************************\n",
      "```json\n",
      "{\n",
      "  \"name\": \"Empire State Building\",\n",
      "  \"address\": \"20 W 34th St\",\n",
      "  \"city\": \"New York\",\n",
      "  \"country\": \"United States\",\n",
      "  \"completion_year\": 1931\n",
      "}\n",
      "```\n",
      "Dict Object:  {'name': 'Empire State Building', 'address': '20 W 34th St', 'city': 'New York', 'country': 'United States', 'completion_year': 1931}\n",
      "name:  Empire State Building\n",
      "completion_year:  1931\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers import OutputFixingParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model='deepseek-chat',\n",
    "    base_url='https://api.deepseek.com',\n",
    "    api_key='sk-7a3d4f4b2ca54d2dbb09e88d3572a242',\n",
    "    streaming=True,  # 保留流式输出功能\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]  # 添加流式回调处理器\n",
    ")\n",
    "\n",
    "class BuildingInfo(BaseModel):\n",
    "    name: str = Field(description=\"Building name\")\n",
    "    address: str = Field(description=\"Building address\")\n",
    "    city: str = Field(description=\"City where the building is located\")\n",
    "    country: str = Field(description=\"Country where the building is located\")\n",
    "    completion_year: int = Field(description=\"Year of completion of the building\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=BuildingInfo)\n",
    "# optional, for fixing the output \n",
    "parser = OutputFixingParser.from_llm(parser=parser, llm=model, max_retries=3) \n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# parser.get_format_instructions() is an encapsulated prompt engineering method for guiding an LLM's to return structured output\n",
    "print(\"format_instructions: \", parser.get_format_instructions())\n",
    "print(\"*\" * 50)\n",
    "print(\"prompt: \", prompt)\n",
    "print(\"*\" * 50)\n",
    "\n",
    "# RunnableSerializable Chaining Format:\n",
    "chain = prompt | model | parser\n",
    "x = {\"query\":\"Tell me about the Empire State Building.\"}\n",
    "response = chain.invoke(x)\n",
    "\n",
    "print(\"\\nDict Object: \", response)\n",
    "print(\"name: \", response[\"name\"])\n",
    "print(\"completion_year: \", response[\"completion_year\"])\n",
    "\n",
    "# print(\"*\" * 50)\n",
    "\n",
    "# # Normal Chaining Format:\n",
    "# x = {\"query\":\"Tell me about the Empire State Building.\"}\n",
    "# x = prompt.invoke(x)\n",
    "# x = model.invoke(x)\n",
    "# response = parser.invoke(x) # or parser.parse(x.content)\n",
    "\n",
    "# print(\"\\nDict Object: \", response)\n",
    "# print(\"name: \", response[\"name\"])\n",
    "# print(\"completion_year: \", response[\"completion_year\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5b0bb6",
   "metadata": {},
   "source": [
    "## Tool Calling with bind_tools - Get Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdcd496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content=\"What's the weather in New York?\", additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_0_d283731e-064a-43d5-be73-da7eed4573dd', 'function': {'arguments': '{\"location\":\"New York\"}', 'name': 'get_wheather'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8'}, id='run--a9d44500-0bc1-42de-8648-1568f8a25b8c-0', tool_calls=[{'name': 'get_wheather', 'args': {'location': 'New York'}, 'id': 'call_0_d283731e-064a-43d5-be73-da7eed4573dd', 'type': 'tool_call'}], usage_metadata={'input_tokens': 115, 'output_tokens': 21, 'total_tokens': 136, 'input_token_details': {'cache_read': 64}, 'output_token_details': {}})]\n",
      "Getting weather for New York\n",
      "[HumanMessage(content=\"What's the weather in New York?\", additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_0_d283731e-064a-43d5-be73-da7eed4573dd', 'function': {'arguments': '{\"location\":\"New York\"}', 'name': 'get_wheather'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8'}, id='run--a9d44500-0bc1-42de-8648-1568f8a25b8c-0', tool_calls=[{'name': 'get_wheather', 'args': {'location': 'New York'}, 'id': 'call_0_d283731e-064a-43d5-be73-da7eed4573dd', 'type': 'tool_call'}], usage_metadata={'input_tokens': 115, 'output_tokens': 21, 'total_tokens': 136, 'input_token_details': {'cache_read': 64}, 'output_token_details': {}}), ToolMessage(content='sunny', name='get_wheather', tool_call_id='call_0_d283731e-064a-43d5-be73-da7eed4573dd')]\n",
      "The weather in New York is currently sunny.content='The weather in New York is currently sunny.' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8'} id='run--b4bd6170-d3bb-4e91-9177-db4a763e5dd4-0' usage_metadata={'input_tokens': 144, 'output_tokens': 9, 'total_tokens': 153, 'input_token_details': {'cache_read': 128}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model='deepseek-chat',\n",
    "    base_url='https://api.deepseek.com',\n",
    "    api_key='sk-7a3d4f4b2ca54d2dbb09e88d3572a242',\n",
    "    streaming=True,  # 保留流式输出功能\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]  \n",
    ")\n",
    "\n",
    "@tool\n",
    "def get_wheather(location: str):\n",
    "    \"\"\"\n",
    "    Function to get the weather for a given location.\n",
    "    \"\"\"\n",
    "    weather = {\n",
    "        \"New York\": \"sunny\",\n",
    "        \"Shanghai\": \"cloudy\",\n",
    "        \"Seoul\": \"rainy\",\n",
    "    }\n",
    "    print(f\"Getting weather for {location}\")\n",
    "    return weather.get(location, \"unknown\")\n",
    "\n",
    "tools = { \"get_wheather\": get_wheather }\n",
    "model_with_tools = model.bind_tools([get_wheather])\n",
    "\n",
    "messages = [HumanMessage(\"What's the weather in New York?\"),]\n",
    "response = model_with_tools.invoke(messages)\n",
    "messages.append(response)\n",
    "print(messages)\n",
    "\n",
    "for tool_call in response.tool_calls:\n",
    "    selected_tool = tools[tool_call[\"name\"]]\n",
    "    tool_msg = selected_tool.invoke(tool_call) #get_wheather(location=\"New York\")\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "print(messages)\n",
    "response = model_with_tools.invoke(messages)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73326847",
   "metadata": {},
   "source": [
    "# LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e707565",
   "metadata": {},
   "source": [
    "## Agent - Booking Hotel and Flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5229563c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "You: \n",
      "I want to fly from Guangzhou to Seoul the morning after tomorrow.\n",
      "\n",
      "Assistant: \n",
      "Calling get_curent_datetime with timezone: Asia/Shanghai\n",
      "Current datetime in Asia/Shanghai : 2025-05-23 20:16:07 CST+0800\n",
      "Calling search_flights with params: {'departure_id': 'CAN', 'arrival_id': 'ICN', 'outbound_date': '2025-05-25', 'return_date': ''}\n",
      "<Response [400]>\n",
      "Calling search_flights with params: {'departure_id': 'CAN', 'arrival_id': 'ICN', 'outbound_date': '2025-05-25', 'return_date': '2025-05-26'}\n",
      "<Response [200]>\n",
      "Here are the available flight options from Guangzhou (CAN) to Seoul (ICN) for the morning after tomorrow (May 25, 2025):\n",
      "\n",
      "### Outbound Flights (May 25, 2025)\n",
      "\n",
      "| Departure Airport Name       | Airline          | Flight Number | Departure Time | Arrival Airport Name       | Arrival Time | Duration | Airplane      | Travel Class | Price (USD) | Legroom | Extensions                                  | Carbon Emissions (kg) |\n",
      "|------------------------------|------------------|---------------|----------------|----------------------------|--------------|----------|---------------|--------------|-------------|---------|---------------------------------------------|------------------------|\n",
      "| Guangzhou Baiyun International Airport | China Eastern    | MU 5732       | 11:25          | Kunming Changshui International Airport | 14:00        | 155 min  | Boeing 737    | Economy      | 300         | 31 in   | Average legroom (31 in), Carbon emissions estimate: 143 kg | 143 |\n",
      "| Kunming Changshui International Airport | China Eastern    | MU 2003       | 17:25          | Incheon International Airport | 22:45        | 260 min  | Boeing 737    | Economy      | 300         | 31 in   | Average legroom (31 in), Carbon emissions estimate: 253 kg | 253 |\n",
      "| Guangzhou Baiyun International Airport | Asiana Airlines  | OZ 356        | 01:15          | Incheon International Airport | 05:45        | 210 min  | Airbus A321neo | Economy      | 347         | 31 in   | Average legroom (31 in), In-seat power & USB outlets, Stream media to your device, Carbon emissions estimate: 174 kg | 174 |\n",
      "| Guangzhou Baiyun International Airport | China Southern   | CZ 337        | 09:35          | Incheon International Airport | 13:55        | 200 min  | Airbus A320neo | Economy      | 468         | 30 in   | Average legroom (30 in), In-seat USB outlet, Carbon emissions estimate: 175 kg | 175 |\n",
      "| Guangzhou Baiyun International Airport | Asiana Airlines  | OZ 370        | 12:25          | Incheon International Airport | 17:00        | 215 min  | Airbus A330    | Economy      | 510         | 31 in   | Average legroom (31 in), In-seat power outlet, On-demand video, Carbon emissions estimate: 158 kg | 158 |\n",
      "| Guangzhou Baiyun International Airport | Korean Air       | KE 866        | 12:40          | Incheon International Airport | 17:15        | 215 min  | Airbus A330    | Economy      | 643         | 32 in   | Above average legroom (32 in), In-seat power & USB outlets, On-demand video, Carbon emissions estimate: 174 kg | 174 |\n",
      "\n",
      "### Return Flights (May 26, 2025)\n",
      "(Not listed as the focus is on the outbound flight.)\n",
      "\n",
      "### Summary\n",
      "- The cheapest option is **China Eastern** for **$300** with a layover in Kunming.\n",
      "- The fastest direct flight is **Asiana Airlines** (OZ 356) for **$347**.\n",
      "- The most comfortable option is **Korean Air** (KE 866) with above-average legroom for **$643**.\n",
      "\n",
      "Would you like to proceed with any of these options or need further assistance?\n",
      "\n",
      "You: \n",
      "I am going to stay there for 3 days, book a hotel for me, the cheapest one.\n",
      "\n",
      "Assistant: \n",
      "Calling search_hotels with params: {'query': 'Seoul', 'check_in_date': '2025-05-25', 'check_out_date': '2025-05-28'}\n",
      "<Response [200]>\n",
      "Here are the cheapest hotel options in Seoul for your stay from May 25 to May 28, 2025:\n",
      "\n",
      "### Cheapest Hotels in Seoul\n",
      "\n",
      "| Properties Name                          | Properties Description                                                                 | Check-in Time | Check-out Time | Price (USD) | Nearby Places                                                                 | Hotel Class | GPS Coordinates         |\n",
      "|------------------------------------------|---------------------------------------------------------------------------------------|---------------|----------------|-------------|-------------------------------------------------------------------------------|-------------|-------------------------|\n",
      "| **Yeoksam Artnouveau Hotel**             | Upscale hotel offering an Italian restaurant & a coffee shop, plus free Wi-Fi.        | 3:00 PM       | 11:00 AM       | $39         | Incheon International Airport (1 hr 42 min by public transport)               | 4-star      | 37.5034, 127.0428      |\n",
      "| **Seoul N Hotel Dongdaemun**             | Streamlined rooms & dorms in a contemporary hostel offering free breakfast & Wi-Fi.   | 3:00 PM       | 11:00 AM       | $31         | Incheon International Airport (1 hr 33 min by public transport)               | 2-star      | 37.5733, 127.0208      |\n",
      "| **Hotel S Seoul**                        | Contemporary hotel featuring relaxed rooms with sitting areas, plus a top-floor lounge & a gym. | 2:00 PM       | 12:00 PM       | $47         | Incheon International Airport (1 hr 8 min by public transport)                | 3-star      | 37.5302, 126.8447      |\n",
      "\n",
      "### Summary\n",
      "- The **cheapest option** is **Seoul N Hotel Dongdaemun** at **$31 per night**.\n",
      "- **Yeoksam Artnouveau Hotel** offers a good balance of price and comfort at **$39 per night**.\n",
      "- **Hotel S Seoul** is slightly more expensive but still affordable at **$47 per night**.\n",
      "\n",
      "Would you like to proceed with booking any of these hotels or need more options?"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from typing import Annotated\n",
    "import json\n",
    "import requests\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "MODEL_URL = 'https://api.deepseek.com'\n",
    "MODEL_API_KEY = 'sk-7a3d4f4b2ca54d2dbb09e88d3572a242'\n",
    "\n",
    "BASE_URL = \"https://serpapi.com/search\"\n",
    "SERPER_API_KEY='39e13214c84bb203818c0f76ce4552fdb310538fd92a2026c93561dc54ff9bff'\n",
    "\n",
    "def search_hotels(\n",
    "    query: Annotated[str, \"The city name or hotel name to search\"], \n",
    "    check_in_date: Annotated[str, \"Hotel Check-in date in YYYY-MM-DD format\"], \n",
    "    check_out_date: Annotated[str, \"Hotel Check-out date in YYYY-MM-DD format\"],\n",
    ") -> Annotated[str, \"Returns a JSON string containing the search results.\"]:\n",
    "    \"\"\"\n",
    "    Function to search hotels based on the given query, check-in date, and check-out date.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"api_key\": SERPER_API_KEY,\n",
    "        \"engine\": \"google_hotels\",\n",
    "        \"q\": query,\n",
    "        \"check_in_date\": check_in_date,\n",
    "        \"check_out_date\": check_out_date,\n",
    "        \"currency\": \"USD\",\n",
    "        \"hl\": \"en\",\n",
    "        \"gl\": \"uk\",\n",
    "    }\n",
    "    print(\"Calling search_hotels with params:\", {\"query\": query, \"check_in_date\": check_in_date, \"check_out_date\": check_out_date})\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    result = response.json()\n",
    "    print(response)\n",
    "    return json.dumps(result)\n",
    "\n",
    "def search_flights(\n",
    "    departure_id: Annotated[str, \"Departure id in IATA format\"], \n",
    "    arrival_id: Annotated[str, \"Arrival id in IATA format\"],\n",
    "    outbound_date: Annotated[str, \"Flight outbound date in YYYY-MM-DD format\"],\n",
    "    return_date: Annotated[str, \"Flight return date in YYYY-MM-DD format\"],\n",
    ") -> Annotated[str, \"Returns a JSON string containing the search results.\"]:\n",
    "    \"\"\"\n",
    "    Function to search flights\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'api_key': SERPER_API_KEY,\n",
    "        \"engine\": \"google_flights\",\n",
    "        \"departure_id\": departure_id,\n",
    "        \"arrival_id\": arrival_id,\n",
    "        \"outbound_date\": outbound_date,\n",
    "        \"return_date\": return_date,\n",
    "        \"currency\": \"USD\",\n",
    "        \"hl\": \"en\",\n",
    "        \"gl\": \"uk\",\n",
    "    }\n",
    "    print(\"Calling search_flights with params:\", {\"departure_id\": departure_id, \"arrival_id\": arrival_id, \"outbound_date\": outbound_date, \"return_date\": return_date})\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    result = response.json()\n",
    "    print(response)\n",
    "    return json.dumps(result)\n",
    "\n",
    "def get_curent_datetime(\n",
    "    zone: Annotated[str, \"Timezone in pytz format to get the current datetime\"],\n",
    ") -> Annotated[str, \"Returns the current datetime in '%Y-%m-%d %H:%M:%S %Z%z' format.\"]:\n",
    "    \"\"\"\n",
    "    Function to get the current datetime in the given timezone.\n",
    "    \"\"\"\n",
    "    print(\"Calling get_curent_datetime with timezone:\", zone)\n",
    "    local_timezone = pytz.timezone(zone)\n",
    "    now = datetime.datetime.now(local_timezone).strftime(\"%Y-%m-%d %H:%M:%S %Z%z\")\n",
    "    print(\"Current datetime in\", zone, \":\", now)\n",
    "    return now\n",
    "\n",
    "prompt = \"\"\"\n",
    "    You are a booking agent, help me to book flights or hotels.\n",
    "\n",
    "    Thought: Understand the user's intention and confirm whether to use the reservation system to complete the task.\n",
    "\n",
    "    Action:\n",
    "    - If booking a flight, convert the departure name and destination name into airport codes.\n",
    "    - If booking a hotel or flight, use the corresponding API to call. Ensure that the necessary parameters are available. If any parameters are missing, use default values or assumptions to proceed.\n",
    "    - If you want to know the current time and date in a specific timezone, for example the date of tomorrow in the place of departure, use the get_curent_datetime API to call.\n",
    "    - If it is not a hotel or flight booking, respond with the final answer only.\n",
    "    - Output the results using a markdown table:\n",
    "    - For flight bookings, separate the outbound and return contents and list them in the order of Departure_airport Name | Airline | Flight Number | Departure Time | Arrival_airport Name | Arrival Time | Duration | Airplane | Travel Class | Price (USD) | Legroom | Extensions | Carbon Emissions (kg).\n",
    "    - For hotel bookings, list them in the order of Properties Name | Properties description | check_in_time | check_out_time | prices | nearby_places | hotel_class | gps_coordinates.\n",
    "\"\"\"\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model='deepseek-chat',\n",
    "    base_url=MODEL_URL,\n",
    "    api_key=MODEL_API_KEY,\n",
    "    streaming=True,  # 保留流式输出功能\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]  # 添加流式回调处理器\n",
    ")\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[search_hotels, search_flights, get_curent_datetime],\n",
    "    checkpointer=checkpointer,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == \"bye\":\n",
    "        break\n",
    "    \n",
    "    print(f\"\\n\\nYou: \\n{user_input}\")\n",
    "    print(\"\\nAssistant: \\n\", end=\"\") \n",
    "    \n",
    "    agent.invoke(\n",
    "        {\"messages\": user_input},\n",
    "        config={\"configurable\": {\"thread_id\": \"1\"}}\n",
    "    )\n",
    "\n",
    "# Example prompts:\n",
    "# 1. I want to fly from Guangzhou to Seoul the morning after tomorrow.\n",
    "# 1. I want to fly from New York to Seoul tomorrow morning.\n",
    "# 2. I am going to stay there for 3 days, book a hotel for me, the cheapest one.\n",
    "# 3. Just show me the best flight and hotel. you decide it for me."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
